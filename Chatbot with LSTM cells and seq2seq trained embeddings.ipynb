{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/q439310/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data frame contains 30000 rows.\n",
      "Dev data frame contains 5928 rows.\n",
      "Adding word 0 to our vocabulary.\n",
      "Adding word 50000 to our vocabulary.\n",
      "Adding word 100000 to our vocabulary.\n",
      "Adding word 150000 to our vocabulary.\n",
      "Adding word 200000 to our vocabulary.\n",
      "Word count in vocab is now 11908, removed 8143 words during cleanup.\n",
      "Data frame contains 30000 rows.\n",
      "Data frame after row cleanup contains 5380 rows.\n",
      "create train, test and validation data sets ...\n",
      "Train set of length: 3766\n",
      "Test set of length: 1210\n",
      "Valid set of length: 404\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "from dataset_helper import prepare_text, train_test_split\n",
    "# load and prepare data\n",
    "v, token_df = prepare_text(max_rows_train_set=30000, count_limit=2, min_length=3, max_length=12, stage='train') # dev or train\n",
    "print(f'create train, test and validation data sets ...')\n",
    "train_set, test_set, valid_set = train_test_split(token_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: <SOS> facil center southampton public sport outdoor activ <EOS> <PAD> <PAD> <PAD>\n",
      "A: <SOS> southampton sport centr <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> instrument disco song incorpor hous music <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> synthes drum machin <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> date afl take control one team <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> januari 6 2016 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> first chopin work gain intern renown <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> rondo op 1 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> relief team travel wenchuan counti <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> two militari transport plane <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> centr provid elect outsid scienc student <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> centr co curricular studi <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> posit malenkov demot <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> deputi prime minist <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> red nucleus control part bodi <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> coordin movement arm leg <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> mani squar mile water boston <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> 41 2 squar mile <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> molecular form found interstellar medium <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> proton molecular hydrogen <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> music station strive play repres music <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> tripl j similar pbs tripl r <EOS> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> layer marin flysch sediment get deposit foreland basin <EOS> <PAD> <PAD>\n",
      "A: <SOS> rise peak underw eros <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> item cloth line display <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> destini child show tour <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> human right aborigin peopl begin improv <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> second half 20th centuri <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> \n",
      "\n",
      "Q: <SOS> three major subgroup slav divid <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "A: <SOS> west slav east slav south slav <EOS> <PAD> <PAD> <PAD> <PAD> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print first 10 QnAs\n",
    "for i in range(15):\n",
    "    ex_q = train_set.iloc[i, 0]\n",
    "    ex_a = train_set.iloc[i, 1]\n",
    "    ex_question = [w for w in v.index2word(ex_q) if w!= '<UNK>']\n",
    "    ex_answer = [w for w in v.index2word(ex_a) if w!= '<UNK>']\n",
    "    # Finally, write out an answer for user\n",
    "    print(\"Q:\", \" \".join(ex_question))\n",
    "    print(\"A:\", \" \".join(ex_answer), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# define parameters\n",
    "input_size = len(v.words)\n",
    "output_size = len(v.words)\n",
    "embedding_size = 300 # 256  -- 300\n",
    "hidden_size = 500 # 256  -- 300\n",
    "lstm_layer = 4\n",
    "dropout = 0.5\n",
    "learning_rate = 0.0001  # -- 0.00001\n",
    "epochs = 100\n",
    "clip = 1\n",
    "BATCH_SIZE = 256 # -- 100\n",
    "teaching_ratio = 0.3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `train_dataloader` with 14 batches!\n",
      "Created `test_dataloader` with 4 batches!\n",
      "Created `test_dataloader` with 1 batches!\n",
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(11908, 300)\n",
      "    (lstm): LSTM(300, 500, num_layers=4, batch_first=True, dropout=0.5)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(11908, 300)\n",
      "    (lstm): LSTM(300, 500, num_layers=4, batch_first=True, dropout=0.5)\n",
      "    (lin_out): Linear(in_features=500, out_features=11908, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (softmax): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from dataset_helper import get_dataloader\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from seq2seq import Seq2Seq\n",
    "import torch\n",
    "\n",
    "train_dataloader, test_dataloader, valid_dataloader = get_dataloader(train_set, test_set, valid_set, BATCH_SIZE)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# instantiate encoder and decoder classes\n",
    "enc = Encoder(input_size, hidden_size, embedding_size, lstm_layer, dropout, BATCH_SIZE).to(device)\n",
    "dec = Decoder(input_size, hidden_size, output_size, embedding_size, lstm_layer, dropout).to(device)\n",
    "# instantiate seq2seq model\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch:   0 | \t Train Loss: 7.706 | \t  Val. Loss: 7.554 | \t  lr: 0.0001\n",
      "\tEpoch:   1 | \t Train Loss: 7.001 | \t  Val. Loss: 6.142 | \t  lr: 0.0001\n",
      "\tEpoch:   2 | \t Train Loss: 5.916 | \t  Val. Loss: 5.841 | \t  lr: 0.0001\n",
      "\tEpoch:   3 | \t Train Loss: 5.596 | \t  Val. Loss: 5.658 | \t  lr: 0.0001\n",
      "\tEpoch:   4 | \t Train Loss: 5.421 | \t  Val. Loss: 5.587 | \t  lr: 0.0001\n",
      "\tEpoch:   5 | \t Train Loss: 5.332 | \t  Val. Loss: 5.631 | \t  lr: 0.0001\n",
      "\tEpoch:   6 | \t Train Loss: 5.286 | \t  Val. Loss: 5.598 | \t  lr: 0.0001\n",
      "\tEpoch:   7 | \t Train Loss: 5.261 | \t  Val. Loss: 5.608 | \t  lr: 0.0001\n",
      "\tEpoch:   8 | \t Train Loss: 5.232 | \t  Val. Loss: 5.616 | \t  lr: 0.0001\n",
      "\tEpoch:   9 | \t Train Loss: 5.221 | \t  Val. Loss: 5.634 | \t  lr: 0.0001\n",
      "\tEpoch:  10 | \t Train Loss: 5.207 | \t  Val. Loss: 5.655 | \t  lr: 1e-05\n",
      "\tEpoch:  11 | \t Train Loss: 5.195 | \t  Val. Loss: 5.613 | \t  lr: 1e-05\n",
      "\tEpoch:  12 | \t Train Loss: 5.189 | \t  Val. Loss: 5.666 | \t  lr: 1e-05\n",
      "\tEpoch:  13 | \t Train Loss: 5.187 | \t  Val. Loss: 5.633 | \t  lr: 1e-05\n",
      "\tEpoch:  14 | \t Train Loss: 5.184 | \t  Val. Loss: 5.622 | \t  lr: 1e-05\n",
      "\tEpoch:  15 | \t Train Loss: 5.189 | \t  Val. Loss: 5.623 | \t  lr: 1e-05\n",
      "\tEpoch:  16 | \t Train Loss: 5.186 | \t  Val. Loss: 5.673 | \t  lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m lr_scheduler \u001B[38;5;241m=\u001B[39m lr_scheduler\u001B[38;5;241m.\u001B[39mReduceLROnPlateau(optimizer, factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# train loop\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteaching_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_out_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Udacity Training/seq2seq/helpers.py:22\u001B[0m, in \u001B[0;36mtrain_loop\u001B[0;34m(model, train_dl, test_dl, optimizer, criterion, scheduler, clip, teaching_ratio, device, epochs, model_out_path)\u001B[0m\n\u001B[1;32m     18\u001B[0m best_valid_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# model, iterator, optimizer, criterion, clip\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteaching_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m     valid_loss \u001B[38;5;241m=\u001B[39m evaluate(model, test_dl, criterion, device)\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m valid_loss \u001B[38;5;241m<\u001B[39m best_valid_loss:\n",
      "File \u001B[0;32m~/Udacity Training/seq2seq/helpers.py:47\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, iterator, optimizer, criterion, clip, teaching_ratio, device)\u001B[0m\n\u001B[1;32m     45\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# run seq2seq model\u001B[39;00m\n\u001B[0;32m---> 47\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mteaching\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mteaching_ratio\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# calc loss\u001B[39;00m\n\u001B[1;32m     49\u001B[0m outputs_flatten \u001B[38;5;241m=\u001B[39m output[\u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, output\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[0;32m~/.pyenv/versions/seq2seq/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Udacity Training/seq2seq/seq2seq.py:35\u001B[0m, in \u001B[0;36mSeq2Seq.forward\u001B[0;34m(self, src, trg, teaching, max_len)\u001B[0m\n\u001B[1;32m     33\u001B[0m inp \u001B[38;5;241m=\u001B[39m trg[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, trg_len):\n\u001B[0;32m---> 35\u001B[0m     output, hidden, cell \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43minp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m     outputs[:, t] \u001B[38;5;241m=\u001B[39m output\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m random\u001B[38;5;241m.\u001B[39mrandom() \u001B[38;5;241m<\u001B[39m teaching:\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;66;03m# use ground truth target token\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/seq2seq/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Udacity Training/seq2seq/decoder.py:44\u001B[0m, in \u001B[0;36mDecoder.forward\u001B[0;34m(self, decoder_input, hidden, cell)\u001B[0m\n\u001B[1;32m     42\u001B[0m decoder_input \u001B[38;5;241m=\u001B[39m decoder_input\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# add a time dimension of size 1\u001B[39;00m\n\u001B[1;32m     43\u001B[0m embedded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(decoder_input))\n\u001B[0;32m---> 44\u001B[0m output, (hidden, cell) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin_out(output\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m))  \u001B[38;5;66;03m# remove the time dimension\u001B[39;00m\n\u001B[1;32m     46\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax(prediction)\n",
      "File \u001B[0;32m~/.pyenv/versions/seq2seq/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.pyenv/versions/seq2seq/lib/python3.11/site-packages/torch/nn/modules/rnn.py:812\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 812\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    813\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    815\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[1;32m    816\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from helpers import evaluate, train_loop\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "model_out_path = 'qna-model.pt'\n",
    "# definer optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# ignore padding index when calculating the loss (<PAD>=3 in vocab)\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=3)\n",
    "# test model with logsoftmax and see if it does help the training to converge better\n",
    "criterion = nn.NLLLoss(ignore_index=3)\n",
    "# lr scheduler to see if this improves the performance of the validation loss\n",
    "lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5)\n",
    "# train loop\n",
    "train_loop(model, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, clip, teaching_ratio, device, epochs, model_out_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.666\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on data it has never seen\n",
    "model_out_path = 'qna-model.pt'\n",
    "model.load_state_dict(torch.load(model_out_path))\n",
    "valid_loss = evaluate(model, valid_dataloader, criterion, device)\n",
    "print(f'Validation Loss: {valid_loss:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to finish the chat.\n",
      " ------------------------------ \n",
      "\n",
      "Question:\t Which first chopin work gained international renown for?\n",
      "Answer:\t <SOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n"
     ]
    }
   ],
   "source": [
    "# inference, load model\n",
    "model = Seq2Seq(enc, dec, device)\n",
    "model.load_state_dict(torch.load(model_out_path))\n",
    "model.eval\n",
    "\n",
    "# define the input question\n",
    "# question = \"What does the urban education institute help run?\"\n",
    "print(\"Type 'exit' to finish the chat.\\n\", \"-\"*30, '\\n')\n",
    "while (True):\n",
    "    question = input(\"> \")\n",
    "    if question.strip() == \"exit\":\n",
    "        break\n",
    "    # clean and tokenize the input question\n",
    "    print(f'Question:\\t {question}')\n",
    "    src = v.word2index(v.clean_text(question))\n",
    "    # convert the tokenized question to a tensor and add a batch dimension\n",
    "    src = torch.tensor(src, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    # generate the answer using the model\n",
    "    output = model(src=src, trg=None, teaching=0, max_len=13)\n",
    "    # convert the output tensor to a list of token IDs\n",
    "    preds = output.argmax(dim=2).tolist()[0]\n",
    "    # convert the token IDs to tokens\n",
    "    answer = v.index2word(preds)\n",
    "    # pretty answer\n",
    "    pretty_answer = ' '.join([w for w in answer]) # .replace('<SOS>', '').replace('<EOS>', '')\n",
    "    # print the predicted answer\n",
    "    print(f'Answer:\\t {pretty_answer}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample questions for chatbot\n",
    "Who led Issacs troops to Cyprus?\n",
    "Who began a program of church reform in the 1100s?\n",
    "Who made fun of the Latin language?\n",
    "Which first chopin work gained international renown for?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}